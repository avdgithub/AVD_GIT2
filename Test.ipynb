{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data once\n",
    "df1 = pd.read_excel('test_4.xlsx')\n",
    "\n",
    "# Create schema for Spark DataFrame\n",
    "df1_schema = StructType([StructField(col_name, StringType(), True) for col_name in df1.columns])\n",
    "\n",
    "# Create Spark DataFrame\n",
    "df = spark.createDataFrame(df1, schema=df1_schema)\n",
    "\n",
    "# Assuming df and dummy_transactions_df are already defined and have a column 'txn_ref_no'\n",
    "\n",
    "# Load the provided CSV files\n",
    "# Load additional CSV files for the second part of the logic\n",
    "cerlic_df = pd.read_excel('Modified_Cerlic_Banks.xlsx')\n",
    "cerlic_df1 = StructType([StructField(col_name, StringType(), True) for col_name in cerlic_df.columns])\n",
    "cerlic_banks_df=spark.createDataFrame(cerlic_df,schema=cerlic_df1)\n",
    "\n",
    "related_party_df = pd.read_excel('Related party statistics .xlsx')\n",
    "related_party_df1 = StructType([StructField(col_name, StringType(), True) for col_name in related_party_df.columns])\n",
    "related_party_df=spark.createDataFrame(related_party_df,schema=related_party_df1)\n",
    "\n",
    "keywords_df = pd.read_csv(\"classification_keywords.csv\")\n",
    "\n",
    "# Load the keywords from a JSON file\n",
    "with open('corporate_keywords.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    corporate_keywords = data['corporate_keywords']\n",
    "\n",
    "# Step 2: Convert the pandas DataFrame to a dictionary for keyword lookup\n",
    "keywords_dict = {}\n",
    "for index, row in keywords_df.iterrows():\n",
    "    keywords_str = str(row['KEYWORDS']).strip()\n",
    "    try:\n",
    "        if keywords_str.startswith(\"[\") and keywords_str.endswith(\"]\"):\n",
    "            keywords_list = ast.literal_eval(keywords_str)\n",
    "        else:\n",
    "            keywords_list = [keyword.strip() for keyword in keywords_str.split(\",\")]\n",
    "        for keyword in keywords_list:\n",
    "            keywords_dict[keyword.lower()] = (row['CATEGORY_LEVEL1'], row['CATEGORY_LEVEL2'])\n",
    "    except Exception as e:\n",
    "        print(\"Skipping this row...\\n\")\n",
    "\n",
    "# Function to set category levels\n",
    "def set_category_levels(base_txn_text, benef_name):\n",
    "    base_txn_text = '' if base_txn_text is None else base_txn_text.lower()\n",
    "    benef_name = '' if benef_name is None else benef_name.lower()\n",
    "    \n",
    "    for keyword, (cat_level1, cat_level2) in keywords_dict.items():\n",
    "        if keyword in base_txn_text or keyword in benef_name:\n",
    "            return (cat_level1, cat_level2)\n",
    "    \n",
    "    return ('OTHER TRANSFER', 'OTHER')\n",
    "\n",
    "# Correcting the returnType to be StructType\n",
    "schema = StructType([\n",
    "    StructField(\"category_level1\", StringType(), False),\n",
    "    StructField(\"category_level2\", StringType(), False)\n",
    "])\n",
    "\n",
    "# Register UDF for category levels\n",
    "category_udf = udf(set_category_levels, schema)\n",
    "\n",
    "def classify_transaction(benef_ifsc, benef_account_no, source, benef_name):\n",
    "    def contains_corporate_keyword(name):\n",
    "        return any(keyword in name.lower() for keyword in corporate_keywords)\n",
    "    \n",
    "    is_corporate = contains_corporate_keyword(benef_name)\n",
    "    \n",
    "    # Check if benef_ifsc starts with \"YESB\"\n",
    "    if benef_ifsc and benef_ifsc.startswith(\"YESB\"):\n",
    "        # If source is not None, then use it to determine the output\n",
    "        if source == 'current':\n",
    "            return 'ybl_corp'\n",
    "        elif source == 'saving':\n",
    "            return 'ybl_ind'\n",
    "        # If source is None, then decide based on is_corporate\n",
    "        else:\n",
    "            return 'ybl_corp' if is_corporate else 'ybl_ind'\n",
    "    # If benef_ifsc does not start with \"YESB\"\n",
    "    else:\n",
    "        return 'non_ybl_cor' if is_corporate else 'non_ybl_ind'\n",
    "\n",
    "classify_transaction_udf = udf(classify_transaction, StringType())\n",
    "# Add a check to see if 'source' column exists in DataFrame and if not, add it with default None values\n",
    "if 'source' not in df.columns:\n",
    "    df = df.withColumn('source', lit(None))\n",
    "\n",
    "# Perform the classification with the modified UDF that handles None source\n",
    "df = df.withColumn('cor_ind_benf', classify_transaction_udf(\n",
    "    col('benef_ifsc'),\n",
    "    col('benef_account_no'),\n",
    "    col('source'),\n",
    "    col('benef_name'))\n",
    ")\n",
    "\n",
    "# First, create the 'categories' struct column\n",
    "df = df.withColumn('categories', category_udf(col('base_txn_text'), col('benef_name')))\n",
    "\n",
    "# Now, you can access the struct fields category_level1 and category_level2 from 'categories'\n",
    "df = df.withColumn('category_level1', col('categories')['category_level1'])\n",
    "\n",
    "# Define the UDF to check if all words in remitter_name are in benef_name\n",
    "def all_words_present(remitter_name, benef_name):\n",
    "    remitter_words = set(remitter_name.lower().split(' '))  # Split by space explicitly\n",
    "    benef_words = set(benef_name.lower().split(' '))        # Split by space explicitly\n",
    "    return remitter_words.issubset(benef_words)\n",
    "\n",
    "# Register the UDF with Spark\n",
    "all_words_present_udf = udf(all_words_present, BooleanType())\n",
    "\n",
    "# Add a new column that uses the UDF to determine if category_level2 should be 'Personal Transfer'\n",
    "df = df.withColumn(\n",
    "    'category_level2',\n",
    "    when(\n",
    "        all_words_present_udf(col('remitter_name'), col('benef_name')),\n",
    "        'PERSONAL TRANSFER'\n",
    "    ).otherwise(\n",
    "        col('categories')['category_level2']\n",
    "    )\n",
    ")\n",
    "\n",
    "df = df.drop('categories', 'source')\n",
    "\n",
    "\n",
    "# Define clean string UDF\n",
    "def clean_string(s):\n",
    "    return s.replace(\" \", \"\").lower() if s else \"\"\n",
    "clean_string_udf = udf(clean_string, StringType())\n",
    "\n",
    "# Clean data\n",
    "cerlic_banks_df = cerlic_banks_df.withColumn(\"Borrower Name\", clean_string_udf(cerlic_banks_df[\"Borrower Name\"]))\n",
    "cerlic_banks_df = cerlic_banks_df.withColumn(\"Name of Lender Bank\", clean_string_udf(cerlic_banks_df[\"Name of Lender Bank\"]))\n",
    "related_party_df = related_party_df.withColumn(\"Related Party Name\", clean_string_udf(related_party_df[\"Related Party Name\"]))\n",
    "related_party_df = related_party_df.withColumn(\"Borrower Name\", clean_string_udf(related_party_df[\"Borrower Name\"]))\n",
    "\n",
    "\n",
    "# Broadcast the dataframes for efficient joins\n",
    "broadcast_cerlic_banks = spark.sparkContext.broadcast(cerlic_banks_df.collect())\n",
    "broadcast_related_party = spark.sparkContext.broadcast(related_party_df.collect())\n",
    "\n",
    "\n",
    "def classify_bank_v2(beneficiary_bank_name, remitter_name, direction, category_level1, category_level2):\n",
    "    # Directly return 'N/A' if direction is 'in'\n",
    "    if direction == 'in':\n",
    "        return 'N/A'\n",
    "\n",
    "    # Check for 'out' direction and specific category conditions\n",
    "    if direction == 'out' and (category_level1 == 'Personal Transfer' or category_level2 in ['Personal Transfer', 'transfer self']):\n",
    "        # Iterate over rows in broadcast_cerlic_banks\n",
    "        for row in broadcast_cerlic_banks.value:\n",
    "            # Check if remitter and beneficiary bank match\n",
    "            if remitter_name == row['Borrower Name'] and beneficiary_bank_name == row['Name of Lender Bank']:\n",
    "                return 'Lending Bank'\n",
    "        # Return 'Non Lending Bank' if no match found\n",
    "        return 'Non Lending Bank'\n",
    "\n",
    "def classify_linkage_v2(benef_name, remitter_name, direction):\n",
    "    if direction == 'in':\n",
    "        return 'N/A'\n",
    "    elif direction == 'out':\n",
    "        for row in broadcast_related_party.value:\n",
    "            if benef_name == row['Related Party Name'] and remitter_name == row['Borrower Name']:\n",
    "                return row['Linkages']\n",
    "    return 'None'\n",
    "\n",
    "def flag_related_party_match(beneficiary_name, remitter_name, direction):\n",
    "    if direction == 'in':\n",
    "        return 'N/A'\n",
    "    elif direction == 'out':\n",
    "        for row in broadcast_related_party.value:\n",
    "            if beneficiary_name == row['Related Party Name'] and remitter_name == row['Borrower Name']:\n",
    "                return 'Y'\n",
    "    return 'N'\n",
    "\n",
    "flag_related_party_match_udf = udf(flag_related_party_match, StringType())\n",
    "classify_bank_with_direction_udf = udf(classify_bank_v2, StringType())\n",
    "classify_linkage_with_direction_udf = udf(classify_linkage_v2, StringType())\n",
    "\n",
    "# Applying the flagging UDF to the dataframe\n",
    "df = df.withColumn('Related Party Match',flag_related_party_match_udf(col('benef_name'), col('remitter_name'),col('direction')))\n",
    "# Applying modified classification functions with direction\n",
    "df = df.withColumn('Bank Classification',classify_bank_with_direction_udf(col('beneficiary_bank_name'),col('remitter_name'),col('direction'),col('category_level1'),col('category_level1')                                                                     ))\n",
    "df = df.withColumn('Linkage Classification',classify_linkage_with_direction_udf(col('beneficiary_bank_name'),col('remitter_name'),col('direction')))\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
